%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Privacy}

Voter privacy implies that a voter is capable of casting his own vote secretly and freely without letting others' parties, namely an adversary, to learn some information about his preferences or interfere in it.\\

In general, the goal of the adversary who attacks voter privacy is to learn some information about the candidate selections of the honest voters. Similarly to \cite{Kiayias2015}, we define an attack against voters privacy as successful, if there is an election result*, for which an adversary is capable of distinguishing how the honest voters voted while it can observe the whole e-voting network, except for untrappable channels, and corrupt some part of honest voters and some entities and also has access to honest voters' receipts. \\

*Obviously, it doesn't include trivial election results, where all voters voted for the same option. \\

During the election process, a voter uses his credentials to cast a vote for some option by running the \textbf{Cast} protocol on a $\vsd$. Since voters are not allowed to have or share a secret that would have helped them to preserve their privacy in case of a corrupted e-voting system, their privacy relies on the trusted entities of the system. There are two wildly known classes of e-voting systems: code-based system and encryption-based systems. The former relies on crypto that is run by the trusted administrator in advance, the latter places its safety on crypto performed inside $\vsd$ during the \textbf{Cast} protocol execution. From a voter point of view, it means that his privacy is protected by trusted administrator and pre-calculated credentials, that would not reveal any sensitive information even if the choice is sent in a plain text, or by trusted $\vsd$ and crypto performed inside it. \\

The approach that we used in this work is the following: an honest voter is allowed to have  \textbf{only one} perfectly hidden from an adversarial eyes interaction and at the end, he provides the adversary with the real and simulated view of the result of this interaction. $\mathcal{A}$ is allowed to observe a network trace of all interactions and play on behalf of corrupted entities and voters. This one perfectly private interaction can be either an act of actually entering voter's preference into $\vsd$ or while a voter receives his credentials. If $\mathcal{A}$  has no advantage in distinguishing real and simulated view over a coin flip, the system is considered private. \\

We formally define the voter privacy via a Voter Privacy game, denotes as $G_{t-priv,<honest~entities>}^{\mathcal{A}, Sim}(1^{\lambda})$, that is played between an adversary $\mathcal{A}$ and a challenger $\mathcal{C}$, that takes as input the security parameter $\lambda$ and returns 1 or 0 depending on whether the adversary wins.  Also, $\mathcal{A}$ is  allowed to corrupt some entities. The choice of the corrupted parties splits the Voter Privacy game into two different scenarios: (1) entities ($\ea$, $\T$) are honest and (2) $\vsd$ is honest. \\

 \section{$\ea$ and $\T$ are honest: $G_{t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda})$}
  \begin{figure}
 \includestandalone[mode=buildnew]{figures/figure1}
        \caption{  $G_{t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$}
\end{figure}

The $\mathcal{C}$'s strategy  in the  $G_{strict,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$ game captures the ability of an honest voter to lie about his vote in code-based e-voting schemes. Suppose, an adversary $\mathcal{A}$ makes a voter $V$ to vote for an option $U_{\mathcal{A}}$.  However, $V$ disobeys and votes for his intent $U_{V}$. If $V$ can fake his credentials  and convince $\mathcal{A}$ that he voted for $U_{\mathcal{A}}$, $V$'s privacy is preserved. This approach is similar to \textit{Demos Privacy} \cite{Kiayias2015}, however instead of faking voter's internal view of the \textbf{Cast} protocol, we fake credentials in a way that would produce a fake internal view of the \textbf{Cast} protocol.\\

We compare \textit{Demos Privacy} and the \textit{Voter Privacy} defined here as follows. Under \textit{Demos Privacy} framework a voter $V$ provides $\mathcal{A}$  with a fake internal view of the \textbf{Cast} protocol and the actual receipt as a proof of obedience but keeps the original credentials in secret. If $\mathcal{A}$ accesses the voter's original credentials, it would immediately detect the lie. Under our \textit{Voter Privacy} definition, a voter $V$ gives $\mathcal{A}$ a fake view, actual receipt and fake credentials. If $\mathcal{A}$ can not distinguish real and fake credentials, it has no way to find out whether $V$ lies or not. \\
 
In the game $G_{t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$, an adversary $\mathcal{A}$ interacts with the challenger $\mathcal{C}$ on behalf of all corrupted voters, $\voc$ and $\vsd$. $\mathcal{C}$ plays the role of honest voters, $\ea$ and $\T$. $\bb$ is completely passive and represents a publicly viewed database. \\

 1)  $\mathcal{A}$ picks and sends two options $U_i^0,U_i^1$ to the challenger $\mathcal{C}$. The first option $U_i^0$ is its intent, the other -- the option that the challenger would use in order to produce an indistinguishable from the intent's ballot and receipt view*. 2) After sending options, $\mathcal{A}$ schedules the   \textbf{Registration} protocol with $\mathcal{C}$ on behalf of some voter $V_i$. 3) $\mathcal{C}$ creates fake credentials $\tilde{s_i}$ and generates real credentials $s_i$ for the voter $V_i$. 4) $\mathcal{C}$ responds $\mathcal{A}$ with a pair of credentials $s_i^0,s_i^1$, where one of the credentials are real and the other were generated using the simulator $Sim$ in a such way, that if $\mathcal{A}$ guesses right and uses the real credentials to cast a vote for $U_i^0$, the produced ballot and internal view of the \textbf{Cast} protocol would be real, otherwise generated ballot would correspond to the option $U_i^1$ and the returned view would be fake. 5) If $\mathcal{A}$ chooses to post the ballot $b_i$ to $\bb$, 6) $\mathcal{C}$  posts exactly the same ballot** to $\bb$. 7) When $\mathcal{A}$ stops the election, $\mathcal{C}$ posts the tally $\tau$ ***. \\\\
\textit{Remarks}:\\
Denote the list of honest voters for which $\mathcal{A}$ chooses to post produced ballot and uses credentials $s_i^0$  as $ \tilde{\mathcal{V}}^0$ and the similar list but for credentials $s_i^1$ as $ \tilde{\mathcal{V}}^1$. \\\\
*If  $\mathcal{C}$ succeeds, $\mathcal{A}$ wouldn't be able to say whether it voted for option $U_i^0$ or $U_i^0$ and $\bb$ would contain both ballots (one for the option $U_i^0$ ,the other for the option $U_i^1$) so the tally wouldn't reveal any information. Example: if $\mathcal{A}$  picks real credential then it casts a vote for the option  $U_i^0$ on behalf of a voter $V_i$, at the same time exactly the same ballot posted by $\mathcal{C}$ would correspond to the fake credentials and the option $U_i^1$. In this case, $\mathcal{A}$ indeed voted for $U_i^0$ as it intended. Else if $\mathcal{A}$ picks the fake credentials and votes for the option $U_i^0$,  its ballot corresponds to the real credentials and  the option $U_i^1$. At the same time, exactly the same ballot posted by $\mathcal{C}$ corresponds to the fake credentials  and the option $U_i^0$. In the last case $\mathcal{A}$ actually voted for $U_i^1$ while thinking it casts vote for $U_i^0$. If this privacy holds,  $\mathcal{A}$ has no idea what option voter $V_i$ voted for. \\\\
** $\mathcal{C}$ should post to the $\bb$ a ballot for the remaining candidate and since $\mathcal{C}$ does not control $\vsd$, it can only post the identical ballot, but \textbf{Tally} it as if it was generated with fake credentials. If  $\mathcal{A}$  voted for $U_i^0$, $\mathcal{C}$ should vote for the $U_i^1$ and vice versa. Otherwise  $\mathcal{A}$  would guess the coin $a$ by simply checking the result of an election. $\mathcal{A}$ is allowed to pick any two options $U_i^0,U_i^1$  and play as many rounds as it likes. Since lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $  not necessarily produce the same result as lists  $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $, the adversary would trivially break privacy. To prevent this, we add challenger's ballots to the $\bb$ and compute the combined tally, namely $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )+ f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} )$. However, if lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ sums to the same result $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, we remove the challenger's ballots  and compute the actual tally. \\\\
*** The tally $\tau$ is posted only if, for every correctly formed adversarial ballot, there is a corresponding challenger's ballot posted on the $\bb$. $\mathcal{A}$ may not post some ballots, however, if it does, then the corresponding challenger's ballot must be posted as well. Otherwise, $\mathcal{A}$ wins the \textit{Voter Privacy} game by simply checking the announced result.  All $\mathcal{A}$'s ballots are tallied based on real credentials, all  $\mathcal{C}$'s ones -- based on fake credentials.   $\mathcal{C}$ removes all its  ballots and computes tally for the adversarial ballots if and only if  lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ are summed up to the same result i.e. $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$. In this case, the announced tally would be $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} )$ if challenger's coin $a=0$ or  $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$ otherwise.\\

 $G_{t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$ defined as follows:\\
\begin{enumerate}
\item $\mathcal{A}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  It provides $\mathcal{C}$ with $\mathcal{V}, \mathcal{P}, \mathcal{U}$.
\item $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated credentials would be returned to $\mathcal{A}$, and starts the election on behalf of $\ea$. 
\item The adversary $\mathcal{A}$ picks two option $U^0_i,U^1_i \in \mathcal{U}$, where $U^0_i$ is its intent and $U^1_i$ is an option that $\mathcal{C}$ would use in order to fool $\mathcal{A}$.  After that, $\mathcal{A}$  and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Registration} protocols, during which all voters receive their credentials and forward them to  $\mathcal{A}$. For each voter $V_i \in \mathcal{V}$, the adversary chooses whether $V_i$ is corrupted:
\begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $\mathcal{A}$ with the real credentials $s_i$, and then they engage in a \textbf{Cast} protocol where the $\mathcal{A}$  vote on behalf of $V_i$ and  $\mathcal{C}$ plays the role of $\ea$.
\item[] --  If $V_i$ is not corrupted, then $\mathcal{C}$ generates real credentials $s_i$  and fake credentials $\tilde{s_i}$ using $Sim$.  $\mathcal{C}$  responds  $\mathcal{A}$ with a pair of simulated and real credentials $(s_0,s_1)$ in order defined by the coin a:\\
$ \begin{cases}
 \text{if} ~~a =0,~~ (s^0_i,s^1_i) = (\tilde{s_i},s_i)  \\ 
 \text{else}~~  (s^0_i,s^1_i) = (s_i,\tilde{s_i})
\end{cases}$
 \item[] -- An honest voter $V_i$ forwards both credentials $s^0_i,s^1_i$ to $\mathcal{A}$
\item[] -- Using one of the credentials $\mathcal{A}$ schedules the \textbf{Cast} protocol execution to vote for an option $U^0_i$ and sends the produced ballot to $\bb$ in the entry that corresponds to the voter $V_i$. As a result of the \textbf{Cast} protocol execution, $\mathcal{A}$ would obtain receipt $r_i$, ballot $b_i$ and the view of the internal state of the voter $V_i$ $view_i$.  During the \textbf{Tally} protocol execution this ballot would be treated as if it was generated with real credentials $s_i$. So, if  $\mathcal{A}$ indeed picked the real credentials, $b_i$ would correspond to the option   $U^0_i$  and $view_i$ would be real. Otherwise, $b_i$ would be a ballot for the option  $U^1_i$ and $view_i$ would be fake. 
\item[] --  If  $\mathcal{A}$ posts a ballot on $\bb$, $\mathcal{C}$ posts exactly the same ballot. During the \textbf{Tally} protocol execution, this ballot would be treated as if it was generated with fake credentials, which means that whatever option in reality $\mathcal{A}$ voted for, $\mathcal{C}$ picked the other option.  
\end{enumerate}
\item Denote the list of honest voter for which $\mathcal{A}$ chooses to post produced ballot and uses credentials $s_i^0$  as $ \tilde{\mathcal{V}}^0$ and the similar list but for credentials $s_i^1$ as $ \tilde{\mathcal{V}}^0$.  If  lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ are summed up to the same result i.e. $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, $\mathcal{C}$ removes all its ballots and executes the \textbf{Tally} protocol on the cleared $\bb$ with real credentials. Otherwise, $\mathcal{C}$ executes the \textbf{Tally} protocol on the $\bb$ that contains both adversarial and challenger's ballots and uses real credentials for adversarial ballots and fake ones for its own. 
\item Finally, $\mathcal{A}$ using all information collected above (including the contents of the BB) outputs a bit $a^*$
\item Denote the set of corrupted voters as $\mathcal{V}_{corr}$ and the set of honest voters as $\hat{\mathcal{V}}= \mathcal{V} \backslash \mathcal{V}_{corr}$. The game returns a bit which is 1 if and only if the following hold true:
\begin{enumerate}
 \item $a = a^*$
 \item $|\mathcal{V}_{corr}| \leq t$ (i.e., the number of corrupted voters is bounded by $t$).
\end{enumerate} 
\end{enumerate}

\textbf{Remark:}\\
$Sim$ works in such a way that fake credentials satisfy both of the following rules: 
\begin{enumerate}
 \item The real credentials and $U_i^0$ option  should give ballot and receipt, which are identical to ballot and receipt produced for the fake credentials and  $U_i^1$ option.
 \item The fake credentials and $U_i^0$ option  should give ballot and receipt, which are identical to ballot and receipt produced for the real credentials and  $U_i^1$ option.
 \end{enumerate}

To understand the logic behind the \textit{Voter Privacy} defined above, consider the following toy examples.\\\\
\textbf{Example 1}\\
We have three voters $V_1,V_2,V_3$ and three possible options $op_1,op_2,op_3$. Challenger's coin $a=0$, so, during the game, the fake credentials are always the first credentials in the credentials pair.
Suppose  $\mathcal{A}$' schedules three vote casting protocols for voters $V_1,V_2,V_3$: \\\\
1)$\boxed{V_1}$:  $\mathcal{A}$ chooses $U^0_1 = op_3, U^1_1 = op_1$ and picks the second credentials for generating the ballot $b_1$ for $op_3$. Since  $\mathcal{A}$ picked the real credentials, the ballot $b_1$ in the \textbf{Tally} process would correctly result in a vote for $op_3$. Meanwhile, $\mathcal{C}$ posts identical to the ballot $b_1$ ballot $\tilde{b_1}$ that corresponds to an option $op_1$.\\
2)$\boxed{V_2}$: $\mathcal{A}$ chooses $U^0_2 = op_1, U^1_2 = op_2$ and picks the first credentials for generating the ballot $b_2$ for $op_1$. Since  $\mathcal{A}$ picked the fake credentials, the ballot $b_2$ in the \textbf{Tally} protocol would result in a vote for $op_2$. Meanwhile, $\mathcal{C}$ posts identical to the ballot $b_2$ ballot $\tilde{b_2}$ that corresponds to an option $op_1$.\\
3)$\boxed{V_3}$:  $\mathcal{A}$ chooses $U^0_3 = op_3, U^1_3 = op_1$ and picks the first credentials for generating the ballot $b_3$ for $op_3$. Since  $\mathcal{A}$ picked the fake credentials, the ballot $b_3$ in the \textbf{Tally} process would  result in a vote for $op_1$. Meanwhile, $\mathcal{C}$ posts identical to the ballot $b_3$ ballot $\tilde{b_3}$ that corresponds to an option $op_3$.\\

At the end of this mini election,  $\mathcal{A}$ would get the following result $op_1 = 3, op_2 = 1, op_3 = 2$. Even though  $\mathcal{A}$'s intention was  to vote for options $op_3,op_1,op_3$, his real choices are $op_3,op_2,op_1$. If privacy holds, $\mathcal{A}$  is unable to understand whether he voted for $U_i^0$ and the challenger for an option $U_i^1$ or vice versa. \\\\
\textbf{Example 2}\\
$\mathcal{C}$'s coin $a=0$, $\mathcal{A}$ sent the challenger options $U_i^0,U_i^1$ and picked the credentials $s_i^0$ for voters $V_0,V_3,V_5$ and the credentials $s_i^1$ for the remaining voters $V_1,V_2,V_4$ to vote for an option $U_i^0$ for all $i \in [0,5]$. Since the coin $a=0$, the left credentials $s_i^0$ are fake. That means, adversarial ballots are actually for options $U_0^1,U_1^0,U_2^0,U_3^1,U_4^0,U_5^1$ instead of $U_0^0,U_1^0,U_2^0,U_3^0,U_4^0,U_5^0$ as it wanted. On the other hand, challenger's ballots are for options $U_0^0,U_1^1,U_2^1,U_3^0,U_4^1,U_5^0$. Suppose that  the sum of all challenger's ballots is denoted as $\tau_c = f(U_0^0) + f(U_1^1) + f(U_2^1) + f(U_3^0) + f(U_4^1) + f(U_5^0)$ and adversarial ones as $\tau_a =  f(U_0^1) + f(U_1^0) + f(U_2^0) + f(U_3^1) + f(U_4^0) + f(U_5^1)$. If $\tau_c$ and $\tau_a$ both give the same result, we can remove all challenger's ballots and compute the election result as  an output of the \textbf{Result} protocol over $\tau_a$. In this case $\mathcal{C}$ would not leak the coin $a$. Equivalence of $\tau_c$ and $\tau_a$ means that $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$.
\begin{definition}[Privacy: $\ea$ and $\T$ are honest]
The e-voting system $\Pi$ achieves voter privacy in case of honest $\T$ and $\ea$  for at most $t$ corrupted voters if there is a PPT simulator $Sim$ such that for any PPT adversary $\mathcal{A}$:\\\\
 $|\Pr[G_{t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m) = 1] - \frac{1}{2}| = negl(\lambda)$
 \end{definition}
 %%%%%%%%%
\section{$\vsd$ and $\T$ are honest: $G_{t-priv,\vsd,\T}^{\mathcal{A},Sim}(1^{\lambda})$}
     \begin{figure}[h!]
 \includestandalone[mode=buildnew]{figures/figure2}
        \caption{ $G_{t-priv,\vsd}^{\mathcal{A},Sim}(1^{\lambda},n,m)$}
\end{figure}
Even though it is possible to achieve voter privacy for trusted $\vsd$ \textbf{only}  (by making the $\T$ unable to decrypt individual votes), such case is rather extreme. The definition of voter privacy below is given for trusted $\vsd$ and $\T$. However, we identify changes that would transform the given definition into \textbf{only} $\vsd$ is trusted case.\\

 In the game $G_{t-priv,\vsd,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$, an adversary $\mathcal{A}$  operates on behalf of the all corrupted voters and all corrupted entities, such as  $\ea$ and $\voc$.  $\mathcal{C}$ plays on behalf of $\vsd$, $\T$ and all honest voters. $\bb$ is completely passive and represents a publicly accessible database.\\
 
 1)  $\mathcal{A}$ picks and sends options $U_i^0, U_i^1$ to the challenger $\mathcal{C}$.  After that $\mathcal{A}$ provides a voter $V_i$ with credentials $s_i$ and 2) schedules the \textbf{Cast} protocol with $\mathcal{C}$ on behalf of $V_i$. 3) $\mathcal{C}$ generates a real ballot, receipt and view and uses $Sim$ to create the fake ones.  4) At the end $\mathcal{C}$ responses with two ballots, receipts and views $b_i^0,r_i^0,view_i^0,b_i^1,r_i^1,view_i^1$, where the order of real and fake output is determined according to a coin $a$. 5) If $\mathcal{A}$ posts a ballot on the $\bb$, $\mathcal{C}$ posts the other ballot*. 6)  When $\mathcal{A}$ stops the election, $\mathcal{C}$ posts the tally $\tau$ ** \\\\
\textit{Remarks:}\\
Denote the list of honest voters for which $\mathcal{A}$ chooses to post the left ballot $b_i^0$  as $ \tilde{\mathcal{V}}^0$ and the similar list but for the right one $b_i^1$ as $ \tilde{\mathcal{V}}^1$. \\\\
*$\mathcal{C}$ should post to the $\bb$ the remaining ballot, otherwise  $\mathcal{A}$  would guess the coin $a$ by simply checking the result of an election. $\mathcal{A}$ is allowed to pick any ballot form the pair $b_i^0,b_i^1$  and play as many rounds as it likes. Since lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $  not necessarily  sums to  the same result as lists  $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $, the adversary would trivially break privacy. To prevent it, we add the challenger's ballots to the $\bb$ and compute the combined tally, namely $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )+ f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} )$. However, if lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ are summed up to the same result i.e. $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, we remove the challenger's ballots and compute the actual tally. \\\\
** The tally $\tau$ is posted only if, for every correctly formed adversarial ballot, there is a corresponding challenger's ballot posted on the $\bb$. $\mathcal{A}$ may not post some ballots, however, if it does, then the corresponding challenger's ballot must be posted as well. Otherwise, $\mathcal{A}$ wins the \textit{Voter Privacy} game by simply checking the announced result.  $\mathcal{C}$ removes all its ballots and computes tally for the adversarial ballots if and only if  lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ produce the same result $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$. In this case, the announced result would be $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} )$ if challenger's coin $a=0$ or  $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$ otherwise.\\

 
The game $G_{t-priv, \vsd,\T}^{\mathcal{A},Sim}(1^{\lambda},n,m)$ is defined as follows:
\begin{enumerate} 
\item $\mathcal{A}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  $\mathcal{A}$ starts an election using $\mathcal{V}, \mathcal{P}, \mathcal{U}$ as input parameters.
\item $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated ballots and receipts would be returned to $\mathcal{A}$.
\item   $\mathcal{A}$ sends to  $\mathcal{C}$ options $U_i^0, U_i^1 \in  \mathcal{U}$, where $U_i^0$ is an option for the real pair ballot and receipt and $U_i^1$ is an option for the fake one.  After that, $\mathcal{A}$ and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Cast}   protocols of all voters which may run concurrently. For each voter $V_i \in \mathcal{V}$, the adversary chooses whether $V_i \in \mathcal{V}$ is corrupted: 
\begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $\mathcal{A}$ with the real ballot and receipt $(b_i,r_i)$.
\item[] --  If $V_i$ is not corrupted, $\mathcal{C}$  provides $\mathcal{A}$ with both simulated and real ballots, receipts and views $(b_i^0, r_i^0,view_i^0) (b_i^1, r_i^1,view_i^1)$ s.t.:\\
$ \begin{cases}
 \text{if} ~~a =0,~~ (b_i^0,r_i^0,view_i^0) = (\tilde{b_i},\tilde{r_i},fake\_view_i) ~~ \text{and} ~~  (b_i^1,r_i^1,view_i^1) = (b_i,r_i,view_i)   \\ 
 \text{else}~~ (b_i^0,r_i^0,view_i) =(b_i,r_i,view_i)~~  \text{and} ~~  (b_i^1,r_i^1,view_i^1) =(\tilde{b_i},\tilde{r_i},fake\_view_i)
\end{cases}$\\ 
where the pair $(b_i, r_i)$ is the ballot and receipt for an adversarial option $U_i^0$ and $(\tilde{b_i},\tilde{r_i})$ is the ballot and receipt for  $U_i^1$ option generated via the simulator $Sim$.
\item[] --  If  $\mathcal{A}$ posts a ballot on $\bb$, $\mathcal{C}$ posts the remaining ballot. 
\end{enumerate}
\item Denote the list of honest voters for which $\mathcal{A}$ chooses to post the ballot  $b_i^0$  as $ \tilde{\mathcal{V}}^0$ and the similar list but for ballots $b_i^1$ as $ \tilde{\mathcal{V}}^0$.  If  lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}, \langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ are summed up to the same result i.e. $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, $\mathcal{C}$ removes all its ballots and executes the \textbf{Tally} protocol on the cleared $\bb$. Otherwise, $\mathcal{C}$ executes the \textbf{Tally} protocol on the $\bb$ that contains ballots for options $U_i^0$ and $U_i^1$. 
\item Finally, $\mathcal{A}$ using all information collected above (including the contents of the BB) outputs a bit $a^*$
\item Denote the set of corrupted voters as $\mathcal{V}_{corr}$ and the set of honest voters as $\tilde{\mathcal{V}}= \mathcal{V} \backslash \mathcal{V}_{corr}$. The game returns a bit which is 1 if and only if the following hold true:
\begin{enumerate}
 \item $a = a^*$
 \item $|\mathcal{V}_{corr}| \leq t$ (i.e., the number of corrupted voters is bounded by $t$).
\end{enumerate}
\end{enumerate}
\begin{remark}
$\mathcal{A}$ can control $\T$ and perform the \textbf{Tally} procedure. However, in such case, it should be impossible for $\T$ to learn the underline vote for any individual ballot or compute the result for $\bb$ that does not contain all ballots $b_i^0,b_i^1$. The only exception is the case when lists  $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $ are summed up to the same tally as lists  $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $ and  $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} $, for this situation $\mathcal{A}$ may perform \textbf{Tally} operation without challenger's ballots. 
\end{remark}
\begin{definition}[Privacy: $\vsd$ and $\T$ are honest]
The e-voting system $\Pi$ achieves voter privacy in case of honest $\vsd$ and $\T$, for at most $t$ corrupted voters , if there is a PPT simulator $Sim$ such that for any PPT adversary $\mathcal{A}$:\\\\
 $|\Pr[G_{t-priv,\vsd,\T}^{\mathcal{A},Sim}(1^{\lambda},n,m) = 1] - \frac{1}{2}| = negl(\lambda)$
 \end{definition}
 \section{Comparison with existing definitions}
The right to an anonymous vote is one of the main requirement for any e-voting system. However, not all information related to an election is considered to be private. For example, some data is collected for public purposes: voter's name and address, whether he participated in elections for the last decade or not etc.  One thing that is universally private everywhere is the content of the ballot, namely how you voted.\\

 Privacy of votes was the subject of great attention in last decades. There are many different approaches that try to capture privacy of voters. A strong security definition can be given  as 1) an ideal functionality, 2) based on the entropy or 3) in the game-based form. The first approach, while being very powerful, results in quite difficult security proofs for real protocols. The second approach implies a weaker security since for it to be secure, the secret's distribution should possess high entropy at least from an adversary's view. The third approach provides the good security guarantees and allows to construct relatively simple security proofs compared to the first simulation-based approach.\\
 
Typically the game-based security definitions are specified as an interaction between  an "adversary" ($\mathcal{A}$) and a "challenger" ($\mathcal{C}$). All honest entities are controlled by $\mathcal{C}$, the rest is played by $\mathcal{A}$. The adversarial goal is to correctly guess a particular piece of hidden information, usually a bit. The game normally specifies what $\mathcal{A}$ can do and what $\mathcal{C}$'s response would be.  The security is defined in the form of the following statement: for all adversaries, the probability of winning the game does not exceed some fixed threshold.\\

A highly helpful survey on game-based privacy definitions has been done by Bernhard et al. in \cite{Bernhard2015}, where they analyse weaknesses of all existing definitions and propose their notion for privacy BPRIV. Based on the results of this survey we compare our privacy definition only with Helios ballot privacy, BPRIV and Demos Privacy definitions. 
 \subsection{Helios. Ballot privacy.}
 Ballot privacy attempts to capture the idea that during its execution a secure protocol does not reveal information about the cast votes, beyond what the result of the election leaks. In some works, ballot privacy defined even stronger: "a voter's vote is not revealed to anyone" \cite{Bernhard2011}. However, in most cases ballot privacy targets specifically vote-casting procedure  and nothing else.\\ 
  
Informally, ballot privacy is satisfied if an adversary in control of arbitrarily many voters cannot distinguish between real ballots and fake ballots, where ballots are replaced by ballots for some fixed vote $\epsilon$ chosen by the adversary. The adversary $\mathcal{A}$ has read access to public $\bb$ and may observe communication channels between the honest parties and $\bb$. Note, that $\mathcal{A}$  is not allowed to corrupt any entities. \\

\theoremstyle{definition}
\begin{definition}[Ballot privacy for Helios \cite{Bernhard2011}]
The challenger $\mathcal{C}$ starts by flipping a coin $a$, which defines in what world the game between $\mathcal{C}$ and an adversary  $\mathcal{A}$ would take place.  If $a=0$, the world is real, otherwise -- fake. Also, $\mathcal{C}$  maintains two bulletin boards $\bb,\bb'$ initialized via the setup algorithm, where $\bb'$ always contains ballots for the real votes.  The adversary $\mathcal{A}$ is always given access $\bb$ and can issue two types of queries: \textbf{vote} and \textbf{ballot}.  In the real world, a \textbf{vote} query causes a ballot for the given vote to be placed on the both $\bb$: hidden $\bb'$ and public $\bb$. In the fake one, the same query causes a ballot for the given vote to be placed on the $\bb'$ and a ballot for $\epsilon$  to be placed on $\bb$. A \textbf{ballot} query always causes the submitted ballot to be processed on both boards. At some point, the adversary $\mathcal{A}$ asks to see the result. The challenger computes tally based on $\bb'$. The adversarial goal is to determine whether the world is real or fake.\\
\end{definition}

The Ballot privacy for Helios contradicts verifiability notion by nature. Intuitively, verifiability means that it's possible to check that a vote was cast as intended, recorded as cast, tallied as recorded and if the tally is encrypted, the final result was decrypted correctly. The definition states that an adversary can not distinguish real and fake world, assuming that he observes communications channels and has access to the public $\bb$ only. In general case, $\bb$ and $\bb'$ contain different sets of votes, though tallying is always done using $\bb'$. The result of an election corresponds to evaluating an arbitrary function $\rho$ that takes a list of votes as input and returns the election result on the underlying votes. Suppose, that there is a proof $\pi$ that the result was tallied as recorded. $\pi$ guarantees that tallying procedure was performed on the given $\bb$ and non-vote has been modified or excluded. If there is such proof, an adversary against ballot privacy could easily check that produced result, even if decrypted correctly, was computed for some other $\bb$ and therefore guess the challenger's coin $a$ with an overwhelming probability. \\

To defend against this attack, $\mathcal{C}$ should be able to fake proof $\pi$. Suppose there is a simulator that can fake the proof $\pi$ without using a global setup. That would mean that secure schemes would not satisfy tally uniqueness since simulator allows any result to be accepted as the valid one. So, the same $\bb$ would have multiple valid election results, which contradicts verifiability. \\ 

A slightly modified privacy definition was given by Bernhard et al in their later work \cite{Bernhard2015}. The extended to global setups version of BPRIV gives a simulator control over the fake global setup, so when an adversary calls to the global setup the simulator is in charge of answering them. The ballot privacy definition BPRIV implies that election results should not contain hidden auxiliary data. The simulated setup grant to a simulator additional powers that are useful in producing valid looking proofs for false statements. However, this approach contradicts the notion of end-to-end verifiability in the standard model \cite{Kiayias2015a}, where all entities can be malicious but still the final result can not be manipulated without a high probability of been caught. Suppose is BPRIV private, then no one can distinguish whether a global setup is fake or real, which means the malicious $\ea$ can generate global setup with a trapdoor and cook up any proofs it likes. 

 \subsection{Demos privacy}
 The only game-based definition we are aware of that compatible with E2E Verifiability in the standard model is \textit{Demos Voter Privacy} defined by Kiayias et al. in\cite{Kiayias2015a}. \\
 
 \textit{Demos Voter Privacy} definition resembles witness indistinguishability of interactive proof system. An adversary's challenge is to distinguish between two pre-defined by the adversary  $\mathcal{A}$ lists of candidate selection that are summed up  to the same tally. \\
 
 The game between an adversary $\mathcal{A}$ and a challenger $\mathcal{C}$ are defined as follows: The adversary defines election parameters: voters, candidates and selects two lists of candidates' selections $\mathcal{L} = <U_l^0, U_l^1>$  that sums up to the same tally. The challenger flips a coin $b$ and starts an election. During the game,   $\mathcal{A}$ schedules all \textbf{Cast} protocols selecting corrupted voters adaptively ($\mathcal{A}$ allowed to corrupt $t$ voters at most). For all honest voters,  $\mathcal{A}$ provides $\mathcal{C}$ with two candidates selections $U_l^0, U_l^1$. $\mathcal{C}$ selects $U_l^b$ as the voting option, runs the \textbf{Cast}  protocol and returns to the adversary (i) the receipt $r_l$ obtained from the protocol, and (ii) if $b = 0$ current view obtained from the protocol or if $b =1$, a simulated view produced by a simulator $\mathcal{S}$. \\
 
 According to the game, for a voter $V_l$, if $b = 0$ $\mathcal{A}$ receives back a receipt $r_l$ the first candidates' selection $U_l^0$ and the current real view of the internal state of the voter obtained from the \textbf{Cast} protocol. Otherwise, for $b = 1$,  $\mathcal{A}$ gets back a receipt $r_l$ the second candidates' selection $U_l^1$ and the simulated view generated by a simulator $\mathcal{S}$. The e-voting scheme $\Pi$ with at most t corrupted voters achieves voter privacy if there exist a simulator $\mathcal{S}$ such that $\mathcal{A}$  has a negligible advantage over a random coin flipping in guessing $b$.\\
 
\begin{definition}[Demos privacy definition.]
The game $G_{DEMOS,t-priv}^{*\mathcal{A}, \mathcal{S}}(1^{\lambda},n,m)$ defined as follows \cite{Kiayias2015a}:\\
  
 During the game $\mathcal{C}$ plays the role of honest voters, $\T$ and $\ea$. $\mathcal{A}$ operates on behalf of corrupted voters and $\vsd$. 
\begin{enumerate}
\item $\mathcal{A}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  It provides $\mathcal{C}$ with $\mathcal{V}, \mathcal{P}, \mathcal{U}$.
\item $\mathcal{C}$ flips a coin $b\in \{0,1\}$ and perform the \textbf{Setup} protocol on input $1^{\lambda},\mathcal{V}, \mathcal{P}, \mathcal{U}$ to obtain $msk,s_1,...,s_n, Pub$; it provides  $\mathcal{A}$ with $Pub$. 
\item The adversary $\mathcal{A}$  and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Cast} protocols of all voters which may run concurrently. For each voter  $V_i \in \mathcal{V}$ the adversary chooses whether $V_i$ is corrupted:
\begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $s_l$ to $\mathcal{A}$, and then they engage in a  \textbf{Cast} protocol where $\mathcal{A}$ plays the role of $V_i$ and  $\mathcal{C}$ plays the role of $\ea$ and $\bb$.
\item[] --  If $V_i$ is not corrupted, $\mathcal{A}$ provides two candidates selections $\langle \mathcal{U}^0_l , \mathcal{U}^1_l \rangle$ to the challenger $\mathcal{C}$. $\mathcal{C}$ operates on $V_l$'s behalf, using  $\mathcal{U}^b_l$ as the $V_l$'s input. The adversary  $\mathcal{A}$ is allowed to observe the network trace of the \textbf{Cast} protocol where  $\mathcal{C}$ plays the role of $V_l$, $\ea$ and $\bb$. When the  \textbf{Cast} protocol terminates, the challenger  $\mathcal{C}$ provides to $\mathcal{A}$: (i) the receipt $\alpha_l$ that voter $V_l$ obtains from the protocol, and (ii) if b = 0, the current view of internal state of the voter $V_l$, $view_l$ that the challenger obtains from the \textbf{Cast} protocol execution; or  a simulated view of the internal state of $V_l$ produced by $\mathcal{S}(view_l)$.
\end{enumerate}
\item $\mathcal{C}$ performs the  \textbf{Tally} protocol playing the role of $\ea$, $\T$  and $\bb$. $\mathcal{A}$ is allowed to observe the network trace of that protocol. 
\item Finally, $\mathcal{A}$ using all information collected above (including the contents of the BB) outputs a bit $b^*$
\end{enumerate}
Denote the set of corrupted voters as $\mathcal{V}_{corr}$ and the set of honest voters as $\tilde{\mathcal{V}}= \mathcal{V} \backslash \mathcal{V}_{corr}$. The game returns a bit which is 1 if and only if the following hold true:
\begin{enumerate}
 \item $b = b^*$
 \item $|\mathcal{V}_{corr}| \leq t$ (i.e., the number of corrupted voters is bounded by $t$).
 \item $f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}} ) = f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}})$ (i.e., the election result w.r.t. the set of voters  $\tilde{\mathcal{V}}$ does not leak b).
\end{enumerate} 
\end{definition}
To prove that Demos privacy implies a weaker level of privacy than we defined, we constructed an modified version of our privacy definition. The difference between the modified and original versions is that in the modified one it is mandatory for  $\mathcal{A}$ to fulfil the following requirement: lists $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}$, $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1}$ and  $\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} $, $\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0}$ that are summed up to the same tally.\\
 
\begin{definition}[Modified original privacy with res. to $\ea$ and $\T$ definition.]

The only difference between the original privacy definition and the modified version is that $\mathcal{A}$ picks its choices $U^0_i$ $U^1_i$ and credentials in a such way that $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, where $ \tilde{\mathcal{V}}^0$ is a list of honest voters for which $\mathcal{A}$ chooses to post produced ballot and uses credentials $s_i^0$ and  $ \tilde{\mathcal{V}}^1$ is a similar list but for credentials $s_i^1$. \\ 

$G_{mod\_ORIG,t-priv,\ea,\T}^{\mathcal{A}, Sim}(1^{\lambda},n,m)$ defined as follows:\\

\begin{enumerate}
\item $\mathcal{A}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  It provides $\mathcal{C}$ with $\mathcal{V}, \mathcal{P}, \mathcal{U}$.
\item $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated credentials would be returned to $\mathcal{A}$, and starts the election on behalf of $\ea$.  
\item The adversary $\mathcal{A}$ picks two option $U^0_i,U^1_i \in \mathcal{U}$, where $U^0_i$ is its intent and $U^1_i$ is an option that $\mathcal{C}$ would use in order to fool $\mathcal{A}$.  After that, $\mathcal{A}$  and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Registration} protocols, during which all voters receive their credentials and forward them to  $\mathcal{A}$. For each voter $V_i \in \mathcal{V}$, the adversary chooses whether $V_i$ is corrupted:
\begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $\mathcal{A}$ with the real credentials $s_i$, and then they engage in a \textbf{Cast} protocol where $\mathcal{A}$  vote on behalf of $V_i$ and  $\mathcal{C}$ plays the role of $\ea$.
\item[] --  If $V_i$ is not corrupted, then $\mathcal{C}$ generates real credentials $s_i$ and fake credentials $\tilde{s_i}$ using $Sim$.  $\mathcal{C}$  responds  $\mathcal{A}$ with a pair of simulated and real credentials $(s_0,s_1)$ in order defined by the coin a:\\
$ \begin{cases}
 \text{if} ~~a =0,~~ (s^0_i,s^1_i) = (\tilde{s_i},s_i)  \\ 
 \text{else}~~  (s^0_i,s^1_i) = (s_i,\tilde{s_i})
\end{cases}$
 \item[] -- An honest voter $V_i$ forwards both credentials $s^0_i,s^1_i$ to $\mathcal{A}$
\item[] -- Using one of the credentials $\mathcal{A}$ schedules the \textbf{Cast} protocol execution to vote for an option $U^0_i$ and sends the produced ballot to $\bb$ in the entry that corresponds to the voter $V_i$. As a result of the \textbf{Cast} protocol execution, $\mathcal{A}$ would obtain receipt $r_i$, ballot $b_i$ and the view of the internal state of the voter $V_i$ $view_i$.  During the \textbf{Tally} protocol execution, this ballot would be treated as if it was generated with real credentials $s_i$. So, if  $\mathcal{A}$ indeed picked the real credentials, $b_i$ would correspond to the option   $U^0_i$  and $view_i$ would be real. Otherwise, $b_i$ would be a ballot for the option  $U^1_i$ and $view_i$ would be fake. 
\item[] -- $\mathcal{A}$ chooses whether to post the produced ballot $b_i$ to the $\bb$ or not. 
\end{enumerate}
\item $\mathcal{C}$ executes the \textbf{Tally} protocol on the $\bb$. 
\item Finally, $\mathcal{A}$ using all information collected above (including the contents of the BB) outputs a bit $a^*$
\item Denote the set of corrupted voters as $\mathcal{V}_{corr}$ and the set of honest voters as $\tilde{\mathcal{V}}= \mathcal{V} \backslash \mathcal{V}_{corr}$. The game returns a bit which is 1 if and only if the following hold true:
\begin{enumerate}
 \item $a = a^*$
 \item $|\mathcal{V}_{corr}| \leq t$ (i.e., the number of corrupted voters is bounded by $t$).
 \item $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$ (i.e., the election result does not leak a), where  $ \tilde{\mathcal{V}}^0$ is the list of honest voters for which $\mathcal{A}$ chooses to post produced ballot and uses credentials $s_i^0$  and $ \tilde{\mathcal{V}}^1$ is the similar list but for credentials $s_i^1$. 
  \end{enumerate} 
\end{enumerate}
\end{definition}

\begin{definition}[Modified original privacy with res. to $\vsd$ and $\T$ definition.]
The game $G_{mod\_ORIG,t-priv, \vsd,\T}^{\mathcal{A},Sim}(1^{\lambda},n,m)$ is defined as follows:
\begin{enumerate} 
\item $\mathcal{A}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  $\mathcal{A}$ starts an election using $\mathcal{V}, \mathcal{P}, \mathcal{U}$ as input parameters.
\item $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated ballots and receipts would be returned to $\mathcal{A}$.
\item   $\mathcal{A}$ sends to  $\mathcal{C}$ options $U_i^0, U_i^1 \in  \mathcal{U}$, where $U_i^0$ is an option for the real ballot and receipt and $U_i^1$ is an option for the fake ones.  After that, $\mathcal{A}$ and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Cast}   protocols of all voters which may run concurrently. For each voter $V_i \in \mathcal{V}$, the adversary chooses whether $V_i \in \mathcal{V}$ is corrupted: 
\begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $\mathcal{A}$ with the real ballot and receipt $(b_i,r_i)$.
\item[] --  If $V_i$ is not corrupted, $\mathcal{C}$  provides $\mathcal{A}$ with a pair of simulated and real ballot,receipt and view $(b_i^0, r_i^0,view_i^0) (b_i^1, r_i^1,view_i^1)$ s.t.:\\
$ \begin{cases}
 \text{if} ~~a =0,~~ (b_i^0,r_i^0,view_i^0) = (\tilde{b_i},\tilde{r_i},fake\_view_i) ~~ \text{and} ~~  (b_i^1,r_i^1,view_i^1) = (b_i,r_i,view_i)   \\ 
 \text{else}~~ (b_i^0,r_i^0,view_i) =(b_i,r_i,view_i)~~  \text{and} ~~  (b_i^1,r_i^1,view_i^1) =(\tilde{b_i},\tilde{r_i},fake\_view_i)
\end{cases}$\\ 
where the pair $(b_i, r_i)$ is the ballot and receipt for an adversarial option $U_i^0$ and $(\tilde{b_i},\tilde{r_i})$ is the ballot and receipt for  $U_i^1$ option generated via the simulator $Sim$.
\item[] --  If  $\mathcal{A}$ posts a ballot on $\bb$, $\mathcal{C}$ posts the remaining ballot. 
\end{enumerate}
\item $\mathcal{C}$ executes the \textbf{Tally} protocol on the $\bb$. 
\item Finally, $\mathcal{A}$ using all information collected above (including the contents of the BB) outputs a bit $a^*$
\item Denote the set of corrupted voters as $\mathcal{V}_{corr}$ and the set of honest voters as $\tilde{\mathcal{V}}= \mathcal{V} \backslash \mathcal{V}_{corr}$. The game returns a bit which is 1 if and only if the following hold true:
\begin{enumerate}
 \item $a = a^*$
 \item $|\mathcal{V}_{corr}| \leq t$ (i.e., the number of corrupted voters is bounded by $t$).
 \item $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, where  $ \tilde{\mathcal{V}}^0$ is the list of honest voters for which $\mathcal{A}$ chooses to post the left ballots $b_i^0$  and $ \tilde{\mathcal{V}}^1$ is the similar list but for right ballots $b_i^1$. 
\end{enumerate}
\end{enumerate}
\end{definition}
% Suppose, there exists an adversary $\mathcal{B}$ that can guess challenger's coin $b$ with probability more than one-half and therefore win the game against "Demos privacy". We will show that such adversary $\mathcal{B}$ can break the privacy defined in this article as well. So, that means that for any simulator $\mathcal{S}$, $\mathcal{B}$ is able to distinguish two lists of candidate selection that sums up to the same tally. \\
 
 %Consider an adversary $\mathcal{A}$ that plays against a challenger $\mathcal{C}$  of our privacy definition and exploits an adversary $\mathcal{B}$ against "Demos privacy".  Since  $\mathcal{B}$  can win the "Demos privacy" game against any simulator  $\mathcal{S}$, it can also win the privacy game against the simulator $\mathcal{S'}$ that the challenger of our privacy game uses for producing simulated credentials. Note, that simulated credentials $\tilde{s}$ are produced by  $\mathcal{S'}$ for the two known in advance options: $U_0, U_1$ in a way, that combination of simulated credentials and an option $U_a$ produces indistinguishable ballot and receipt from the ballot and receipt obtained for real credentials and the remaining $U_{1-a}$ option, where $a$ is a coin. For example, consider a code based e-voting system, where chosen voting code is a receipt and a voter can select from options 'YES', 'MAYBE' and 'NO'. Suppose $\mathcal{A}$ sends to $\mathcal{C}$  options $(U_0, U_1) = ('YES,'NO')$, then  a possible real ballot is "YES - 1, MAYBE - 5, NO - 2" and a fake one can be formed as "YES - 2, MAYBE - 3, NO - 1".  The fake credentials should have swapped voting codes for the selected by  $\mathcal{A}$ candidates comparing to the same options in the real credentials. $\mathcal{A}$ can pick one of the credentials and vote for the first option 'YES' and the produced ballot would always correspond to the other credentials and option 'NO'.\\
 
%  $\mathcal{A}$ forwards to $\mathcal{C}$ all setup parameters received from $\mathcal{B}$. For all corrupted voters $\mathcal{A}$ simply forwards all $\mathcal{B}$ requests to  $\mathcal{C}$  and returns back all  $\mathcal{C}$ 's responses. For an honest voter $V_l$, $\mathcal{A}$ forwards a pair $U_l^0, U_l^1$ to the challenger and receives a pair for credentials $s_0,s_1$, where $s_a$ is real credentials.  $\mathcal{A}$ always picks the first credentials $s_0$ and uses it to submit a vote for an option $U_l^0$.  $\mathcal{C}$ responses with a two pairs of ballots and receipts $(r_0,b_0)(r_1,b_1)$. If challenger's coin $a = 0$, then $s_0$ is real credentials and $r_0,b_0$ is the ballot and receipt for an option $U_l^0$. Otherwise, $s_0$ is fake credentials and cote casting procedure for an option $U_0$ produces ballot and receipt $r_0,b_0$ which is indistinguishable from the ballot and receipt obtained after voting with real credentials for an option $U_l^1$. Thus,  $\mathcal{A}$ always returns to $\mathcal{B}$ $r_0,b_0$, where $b_0$ is an internal view. In case, when $a=0$, $r_0,b_0$ are ballot and receipt for an option $U_l^0$ and, if $a=1$ $r_0,b_0$ corresponds to option $U_l^1$. At the end of the game, $\mathcal{A}$ outputs $\mathcal{B}$'s guess. 
 Suppose there exists an adversary $\mathcal{B}$ that wins the \textit{Demos Privacy} game with the probability more than one-half. We will show that it's possible to construct an adversary $\mathcal{A}$ that exploits $\mathcal{B}$ and breaks the modified original privacy. \\
 
Consider the \textit{Modified Voter Privacy} game in case when $\ea$ and $\T$ are trusted. We can construct an adversary $\mathcal{A}$, that exploits $\mathcal{B}$, and wins the game against \textit{Modified Voter Privacy}.\\
$\mathcal{B}$ -- $\mathcal{A}$ -- $\mathcal{C}$ (where $\mathcal{C}$ is the challenger against Modified original privacy) interaction: 
\begin{enumerate}
\item $\mathcal{B}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  It provides $\mathcal{A}$ with $\mathcal{V}, \mathcal{P}, \mathcal{U}$.
 \item $\mathcal{A}$ forwards to $\mathcal{C}$  lists $\mathcal{V}, \mathcal{P}, \mathcal{U}$ defined by $\mathcal{B}$
 \item  $\mathcal{C}$ starts the election on behalf of $\ea$. Also, $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated credentials would be returned to $\mathcal{A}$. 
 \item The adversary $\mathcal{A}$  and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Registration} protocols, during which all voters receive their credentials and forward them to $\mathcal{A}$. At the same time, $\mathcal{A}$ simulates the challenger for demos privacy game for $\mathcal{B}$ and schedules the  \textbf{Cast}  protocol with $\mathcal{B}$. For each voter  $V_i \in \mathcal{V}$ the adversary $\mathcal{B}$  chooses whether $V_i$ is corrupted and $\mathcal{A}$ forwards this decision to $\mathcal{C}$ :
 \begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{C}$ provides $s_i$ to $\mathcal{A}$,  $\mathcal{A}$ forwards $s_i$ to $\mathcal{B}$ and then they engage in a \textbf{Cast} protocol where  $\mathcal{B}$ plays the role of $V_i$ and  $\mathcal{C}$ plays the role of $\ea$ and $\bb$, while $\mathcal{A}$ simply transfers information from $\mathcal{B}$ to $\mathcal{C}$.
\item[] --  If $V_i$ is not corrupted, $\mathcal{B}$ provides two candidates selections $\langle \mathcal{U}^0_i , \mathcal{U}^1_i \rangle$ to $\mathcal{A}$. $\mathcal{A}$ forwards this pair to $\mathcal{C}$.  $\mathcal{C}$ generates real credentials $s_i$ and fake credentials $\tilde{s_i}$ using $Sim$. $\mathcal{A}$ receives a pair of simulated and real credentials $(s_0,s_1)$ in order defined by the coin a:
$ \begin{cases}
 \text{if} ~~a =0,~~ (s^0_i,s^1_i) = (\tilde{s_i},s_i)  \\ 
 \text{else}~~  (s^0_i,s^1_i) = (s_i,\tilde{s_i})
\end{cases}$\\
$\mathcal{A}$ always uses the first credentials $s^0_i$ to schedule the \textbf{Cast} protocol execution and vote for an option $U^0_i$. Since  $\mathcal{A}$  controls $\vsd$, it produces ballot $b_i$ and posts it to the $\bb$ in the entry that corresponds to the voter $V_i$. As a result of the \textbf{Cast} protocol execution, $\mathcal{A}$ would obtain: receipt $r_i$, ballot $b_i$ and the view of the internal state of the voter $V_i$ i.e. $view_i$.  During the \textbf{Tally} protocol execution this ballot would be treated as if it was generated with real credentials $s_i$. So, if  $\mathcal{A}$ indeed picked the real credentials, $b_i$ would correspond to the option   $U^0_i$  and $view_i$ would be real. Otherwise, $b_i$ would be a ballot for the option  $U^1_i$ and $view_i$ would be fake. The adversary  $\mathcal{B}$ is allowed to observe the network trace of the \textbf{Cast} protocol where  $\mathcal{A}$ plays the role of $V_l$ and $\vsd$ and  $\mathcal{C}$ plays on behalf of $\ea$. When the  \textbf{Cast} protocol terminates, $\mathcal{A}$ provides to $\mathcal{B}$: (i) the receipt $r_i$ that voter $V_i$ obtains from the protocol, and (ii) $view_i$ \end{enumerate}
\item $\mathcal{C}$ performs the \textbf{Tally} protocol playing the role of $\ea$, $\T$  and $\bb$. Since \textit{Demos Privacy} implies that  $f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}} ) = f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}})$ and  $\mathcal{A}$ always posts all ballots and always uses the first credentials $s_i^0$, then  $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, where $\tilde{\mathcal{V}}^1$ is empty.  $\mathcal{A}$ and  $\mathcal{B}$ are allowed to observe the network trace of that protocol. 
\item Finally, $\mathcal{B}$ using all information collected above (including the contents of the BB) outputs a bit $b^*$
\item $\mathcal{A}$ returns $1 - b^*$
 \end{enumerate} 
 
 If the challenger's  $\mathcal{C}$ coin $a=0$, then the first credentials $s^0_i$ are always fake. Since $\mathcal{A}$ always uses $s^0_i$ to schedule the \textbf{Cast} protocol execution with $\mathcal{C}$ and vote for an option $U^0_i$, as a result of the execution $\mathcal{A}$ would obtain receipt $r_i$, ballot $b_i$ that is actually a vote for $U^1_i$  and the fake view of the internal state of the voter $V_i$. This case corresponds to the coin $b=1$ in the Demos privacy game. \\
 
 Else if $\mathcal{C}$'s coin $a=1$, $s^0_i$ are always real credentials. As a result of the \textbf{Cast}  protocol execution $\mathcal{A}$ would obtain receipt $r_i$, ballot $b_i$ that is indeed a vote for $U^0_i$  and the real view of the internal state of the voter $V_i$. This case corresponds to the coin $b=0$ in the Demos privacy game.\\
 
By assumption, $\mathcal{B}$ has an advantage over a coin flipping in winning the demos privacy game. This means that  $\mathcal{B}$ is capable of guessing coin $b$ with probability more than one-half.  $\mathcal{A}$ returns $1-b^*$, where $b^*$ is the $\mathcal{B}$'s guess. The above states that $\mathcal{A}$ is capable of winning the modified privacy game against  the challenger $\mathcal{C}$ with probability more than random coin flipping, which means $\mathcal{A}$ breaks modified privacy definition. \\

So, if there is an adversary that breaks \textit{Demos Privacy}, there is an adversary that exploits it in order to  break \textit{Modified Voter Privacy} for the case of trusted $\ea$ and $\T$. \\

We will show, that \textit{Demos Privacy} is also weaker than  \textit{Modified Voter Privacy} for the case of trusted $\vsd$ and $\T$. Suppose there exists an adversary $\mathcal{B}$ that wins the \textit{Demos Privacy} game with the probability more than one-half. We will show that it's possible to construct an adversary $\mathcal{A}$ that exploits $\mathcal{B}$ and breaks the \textit{Modified Voter Privacy} in case of trusted $\vsd$ and $\T$.\\

$\mathcal{B}$ -- $\mathcal{A}$ -- $\mathcal{C}$ (where  $\mathcal{C}$ is the challenger against Modified original privacy) interaction: 
\begin{enumerate}
\item $\mathcal{B}$ on input $1^{\lambda},n,m$ defines a set of voters  $\mathcal{V} = \{V_1,...,V_n\}$, chooses a list of candidates  $\mathcal{P} = \{P_1,...,P_m\}$ and the set of allowed candidates' selections $\mathcal{U}$.  It provides $\mathcal{A}$ with $\mathcal{V}, \mathcal{P}, \mathcal{U}$.
 \item $\mathcal{A}$ starts the election on behalf of $\ea$.
 \item $\mathcal{C}$ flips a coin $a \leftarrow \{0,1\}$ to define an order according to which real and simulated credentials would be returned to $\mathcal{A}$. 
 \item The adversary $\mathcal{A}$  and $\mathcal{C}$ engage in an interaction where $\mathcal{A}$ schedules the \textbf{Cast} protocols. At the same time, $\mathcal{A}$ simulates the challenger for demos privacy game for $\mathcal{B}$ and schedules the  \textbf{Cast}  protocol with $\mathcal{B}$. For each voter  $V_i \in \mathcal{V}$ the adversary $\mathcal{B}$  chooses whether $V_i$ is corrupted and $\mathcal{A}$ forwards this decision to $\mathcal{C}$ :
 \begin{enumerate}
\item[] -- If $V_i$ is corrupted, then $\mathcal{A}$ provides $s_i$ to $\mathcal{B}$ and then they engage in a \textbf{Cast} protocol where  $\mathcal{B}$ plays the role of $V_i$ and  $\mathcal{C}$ plays the role of $\vsd$, while $\mathcal{A}$ simply transfers information from $\mathcal{B}$ to $\mathcal{C}$.
\item[] --  If $V_i$ is not corrupted, $\mathcal{B}$ provides two candidates selections $\langle \mathcal{U}^0_i , \mathcal{U}^1_i \rangle$ to $\mathcal{A}$. $\mathcal{A}$ forwards this pair to $\mathcal{C}$.  $\mathcal{C}$ returns $(r_i^0,b_i^0,view_i^0,r_i^1,b_i^1,view_i^1$ in order defined by the coin a:\\
$ \begin{cases}
 \text{if} ~~a =0,~~ (r_i^0,b_i^0,view_i^0,r_i^1,b_i^1,view_i^1) = (\tilde{r_i},\tilde{b_i},fake\_view_i,r_i,b_i,view_i)  \\ 
 \text{else}~~  (r_i^0,b_i^0,view_i^0,r_i^1,b_i^1,view_i^1) = (r_i,b_i,view_i,(\tilde{r_i},\tilde{b_i},fake\_view_i)
\end{cases}$\\
$\mathcal{A}$ always sends the first receipt and view $r^0_i,view_i^0$ to  $\mathcal{B}$.  If  $\mathcal{A}$ indeed picked the real pair, $r_i^0,b_i^0$ would correspond to the option  $U^0_i$  and $view_i^0$ would be real. Otherwise, $r_i^0,b_i^0$ would be the ballot and receipt for the option  $U^1_i$ and $view_i^0$ would be fake. The adversary  $\mathcal{B}$ is allowed to observe the network trace of the \textbf{Cast} protocol where $\mathcal{C}$ plays the role of $V_l$ and $\vsd$ and  $\mathcal{A}$ plays on behalf of $\ea$ and $\bb$. 
\item $\mathcal{C}$ performs the \textbf{Tally} protocol playing the role of $\T$. Since \textit{Demos Privacy} implies that  $f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}} ) = f(\langle \mathcal{U}^0_l \rangle _{V_l \in \tilde{\mathcal{V}}})$ and  $\mathcal{A}$ always posts the first ballot, then  $f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} ) + f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) =  f(\langle \mathcal{U}^0_i \rangle _{V_i \in \tilde{\mathcal{V}}^1} ) +  f(\langle \mathcal{U}^1_i \rangle _{V_i \in \tilde{\mathcal{V}}^0} )$, where $\tilde{\mathcal{V}}^1$ is empty.  $\mathcal{A}$ and  $\mathcal{B}$ are allowed to observe the network trace of that protocol. 
\item Finally, $\mathcal{B}$ using all information collected above (including the contents of the BB) outputs a bit $b^*$
\item $\mathcal{A}$ returns $1 - b^*$
 \end{enumerate} 
  \end{enumerate} 
 
If the challenger's  $\mathcal{C}$ coin $a=0$, then the first values $r^0_i,b_i^0,view_i^0$ are always fake. Since $\mathcal{A}$ always uses $r^0_i,b_i^0,view_i^0$, $\mathcal{B}$ would obtain: receipt $r_i$, ballot $b_i$ that is actually a vote for $U^1_i$  and the fake view of the internal state of the voter $V_i$. This case corresponds to the coin $b=1$ in the \textit{Demos Privacy} game. \\

Else if $\mathcal{C}$'s coin $a=1$, values $r^0_i,b_i^0,view_i^0$ are always real. As a result of the \textbf{Cast}  protocol execution $\mathcal{B}$ would obtain: receipt $r_i$, ballot $b_i$ that is indeed a vote for $U^0_i$  and the real view of the internal state of the voter $V_i$. This case corresponds to the coin $b=0$ in the \textit{Demos Privacy} game.\\
 
By assumption, $\mathcal{B}$ has an advantage over a coin flipping in winning the demos privacy game. This means that  $\mathcal{B}$ is capable of guessing coin $b$ with probability more than one-half.  $\mathcal{A}$ returns $1-b^*$, where $b^*$ is the $\mathcal{B}$'s guess. The above states that $\mathcal{A}$ is capable of wining the modified privacy game against  the challenger $\mathcal{C}$ with probability more than random coin flipping, which means $\mathcal{A}$ breaks \textit{Modified Voter Privacy} definition.\\ 

We prove that if there exist a successful adversary agains \textit{Demos Privacy}, then there also exist an adversary who breaks the \textit{Modified Voter Privacy}. Therefore, \textit{Demos Privacy} implies weaker level of privacy than \textit{Modified Voter Privacy} for both cases of collision. On the other hand, \textit{Modified Voter Privacy} is the particular case of \textit{Voter Privacy}. This means that if \textit{Demos Privacy} is broken than \textit{Voter Privacy} is also would be broken.The \textit{Voter Privacy} game implies at least the \textit{Demos Privacy}.  